{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFM - no context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 09:27:53.318413: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-20 09:27:53.481218: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-20 09:27:54.154720: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-20 09:27:54.158429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-20 09:27:57.323217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Required modules\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id:token</th>\n",
       "      <th>item_id:token</th>\n",
       "      <th>rating:float</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5C28F393B23BB894523AE7126A7AE445</td>\n",
       "      <td>219668</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3FA27F6E8AC712A82C69C4EDD8B912CC</td>\n",
       "      <td>223860</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B99CFBB5411EDC8881D13B7A4B313ADA</td>\n",
       "      <td>75680</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3FA27F6E8AC712A82C69C4EDD8B912CC</td>\n",
       "      <td>224783</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7CEFF5C32BA1F3B186E7838C7D3FE25E</td>\n",
       "      <td>222984</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      user_id:token  item_id:token  rating:float\n",
       "0  5C28F393B23BB894523AE7126A7AE445         219668             5\n",
       "1  3FA27F6E8AC712A82C69C4EDD8B912CC         223860             5\n",
       "2  B99CFBB5411EDC8881D13B7A4B313ADA          75680             5\n",
       "3  3FA27F6E8AC712A82C69C4EDD8B912CC         224783             5\n",
       "4  7CEFF5C32BA1F3B186E7838C7D3FE25E         222984             5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "use_cols = ['user_id:token', 'item_id:token', 'rating:float']\n",
    "data = pd.read_csv('./dataset/tripadvisor/tripadvisor.inter', usecols=use_cols)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the user_id column\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "data['user_id:token'] = user_encoder.fit_transform(data['user_id:token'].values)\n",
    "\n",
    "# Encoding the item_id column\n",
    "item_encoder = LabelEncoder()\n",
    "data['item_id:token'] = item_encoder.fit_transform(data['item_id:token'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns\n",
    "\n",
    "data.columns = ['user_id', 'item_id', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of unique users and movies\n",
    "\n",
    "num_users = data['user_id'].nunique()\n",
    "num_movies = data['item_id'].nunique()\n",
    "\n",
    "# Define embedding size\n",
    "\n",
    "embedding_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (train_data.shape[1] - 1,)\n",
    "\n",
    "# Define input layers\n",
    "user_input = tf.keras.layers.Input(shape=(1,))\n",
    "movie_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "# Define user embedding\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, embedding_size, input_length=1)(user_input)\n",
    "user_embedding = tf.keras.layers.Flatten()(user_embedding)\n",
    "\n",
    "# Define movie embedding\n",
    "movie_embedding = tf.keras.layers.Embedding(num_movies, embedding_size, input_length=1)(movie_input)\n",
    "movie_embedding = tf.keras.layers.Flatten()(movie_embedding)\n",
    "\n",
    "# Concatenate user and movie embeddings\n",
    "concat = tf.keras.layers.concatenate([user_embedding, movie_embedding])\n",
    "\n",
    "# Define FM part\n",
    "fm = tf.keras.layers.Dense(1, activation=None)(concat)\n",
    "\n",
    "# Define DNN part\n",
    "dnn = tf.keras.layers.Dense(64, activation='relu')(concat)\n",
    "dnn = tf.keras.layers.Dense(32, activation='relu')(dnn)\n",
    "dnn = tf.keras.layers.Dense(1, activation=None)(dnn)\n",
    "\n",
    "# Concatenate FM and DNN parts\n",
    "concat = tf.keras.layers.concatenate([fm, dnn])\n",
    "\n",
    "# Define output layer\n",
    "output = tf.keras.layers.Flatten()(concat)\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Model(inputs=[user_input, movie_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "178/178 [==============================] - 1s 2ms/step - loss: 17.4629 - mae: 4.0704 - val_loss: 17.0263 - val_mae: 4.0184\n",
      "Epoch 2/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 15.6091 - mae: 3.8253 - val_loss: 14.4085 - val_mae: 3.6521\n",
      "Epoch 3/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 12.3984 - mae: 3.3063 - val_loss: 10.9244 - val_mae: 3.0089\n",
      "Epoch 4/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 9.6346 - mae: 2.6703 - val_loss: 9.2022 - val_mae: 2.5072\n",
      "Epoch 5/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 8.8174 - mae: 2.4009 - val_loss: 8.8947 - val_mae: 2.4053\n",
      "Epoch 6/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 8.6070 - mae: 2.3497 - val_loss: 8.7323 - val_mae: 2.3765\n",
      "Epoch 7/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 8.4300 - mae: 2.3192 - val_loss: 8.5760 - val_mae: 2.3532\n",
      "Epoch 8/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 8.2541 - mae: 2.2909 - val_loss: 8.4200 - val_mae: 2.3325\n",
      "Epoch 9/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 8.0756 - mae: 2.2634 - val_loss: 8.2587 - val_mae: 2.3107\n",
      "Epoch 10/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 7.8936 - mae: 2.2359 - val_loss: 8.0924 - val_mae: 2.2880\n",
      "Epoch 11/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 7.7067 - mae: 2.2079 - val_loss: 7.9228 - val_mae: 2.2661\n",
      "Epoch 12/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 7.5152 - mae: 2.1795 - val_loss: 7.7474 - val_mae: 2.2427\n",
      "Epoch 13/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 7.3184 - mae: 2.1503 - val_loss: 7.5665 - val_mae: 2.2182\n",
      "Epoch 14/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 7.1169 - mae: 2.1201 - val_loss: 7.3820 - val_mae: 2.1935\n",
      "Epoch 15/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 6.9110 - mae: 2.0892 - val_loss: 7.1943 - val_mae: 2.1683\n",
      "Epoch 16/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 6.7012 - mae: 2.0576 - val_loss: 7.0021 - val_mae: 2.1417\n",
      "Epoch 17/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 6.4876 - mae: 2.0246 - val_loss: 6.8074 - val_mae: 2.1149\n",
      "Epoch 18/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 6.2711 - mae: 1.9909 - val_loss: 6.6069 - val_mae: 2.0841\n",
      "Epoch 19/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 6.0520 - mae: 1.9560 - val_loss: 6.4100 - val_mae: 2.0584\n",
      "Epoch 20/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 5.8316 - mae: 1.9209 - val_loss: 6.2061 - val_mae: 2.0268\n",
      "Epoch 21/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 5.6098 - mae: 1.8842 - val_loss: 6.0042 - val_mae: 1.9978\n",
      "Epoch 22/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 5.3875 - mae: 1.8476 - val_loss: 5.7975 - val_mae: 1.9631\n",
      "Epoch 23/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 5.1654 - mae: 1.8096 - val_loss: 5.5951 - val_mae: 1.9326\n",
      "Epoch 24/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 4.9449 - mae: 1.7716 - val_loss: 5.3915 - val_mae: 1.8993\n",
      "Epoch 25/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 4.7250 - mae: 1.7326 - val_loss: 5.1902 - val_mae: 1.8663\n",
      "Epoch 26/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 4.5076 - mae: 1.6930 - val_loss: 4.9926 - val_mae: 1.8353\n",
      "Epoch 27/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 4.2936 - mae: 1.6534 - val_loss: 4.7939 - val_mae: 1.7995\n",
      "Epoch 28/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 4.0823 - mae: 1.6130 - val_loss: 4.5961 - val_mae: 1.7610\n",
      "Epoch 29/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 3.8751 - mae: 1.5719 - val_loss: 4.4077 - val_mae: 1.7296\n",
      "Epoch 30/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 3.6728 - mae: 1.5314 - val_loss: 4.2182 - val_mae: 1.6921\n",
      "Epoch 31/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 3.4752 - mae: 1.4905 - val_loss: 4.0334 - val_mae: 1.6536\n",
      "Epoch 32/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 3.2837 - mae: 1.4493 - val_loss: 3.8551 - val_mae: 1.6188\n",
      "Epoch 33/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 3.0973 - mae: 1.4082 - val_loss: 3.6824 - val_mae: 1.5839\n",
      "Epoch 34/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 2.9176 - mae: 1.3672 - val_loss: 3.5156 - val_mae: 1.5497\n",
      "Epoch 35/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 2.7446 - mae: 1.3265 - val_loss: 3.3550 - val_mae: 1.5157\n",
      "Epoch 36/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 2.5785 - mae: 1.2861 - val_loss: 3.1956 - val_mae: 1.4756\n",
      "Epoch 37/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 2.4198 - mae: 1.2460 - val_loss: 3.0482 - val_mae: 1.4437\n",
      "Epoch 38/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 2.2691 - mae: 1.2066 - val_loss: 2.9068 - val_mae: 1.4108\n",
      "Epoch 39/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 2.1259 - mae: 1.1677 - val_loss: 2.7692 - val_mae: 1.3743\n",
      "Epoch 40/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.9906 - mae: 1.1297 - val_loss: 2.6425 - val_mae: 1.3429\n",
      "Epoch 41/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.8629 - mae: 1.0919 - val_loss: 2.5244 - val_mae: 1.3152\n",
      "Epoch 42/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.7439 - mae: 1.0563 - val_loss: 2.4083 - val_mae: 1.2809\n",
      "Epoch 43/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.6328 - mae: 1.0219 - val_loss: 2.3025 - val_mae: 1.2504\n",
      "Epoch 44/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.5297 - mae: 0.9885 - val_loss: 2.2034 - val_mae: 1.2218\n",
      "Epoch 45/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.4340 - mae: 0.9563 - val_loss: 2.1138 - val_mae: 1.1973\n",
      "Epoch 46/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.3470 - mae: 0.9260 - val_loss: 2.0279 - val_mae: 1.1685\n",
      "Epoch 47/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.2668 - mae: 0.8969 - val_loss: 1.9505 - val_mae: 1.1431\n",
      "Epoch 48/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.1939 - mae: 0.8703 - val_loss: 1.8798 - val_mae: 1.1197\n",
      "Epoch 49/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.1284 - mae: 0.8450 - val_loss: 1.8161 - val_mae: 1.0992\n",
      "Epoch 50/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.0693 - mae: 0.8220 - val_loss: 1.7582 - val_mae: 1.0790\n",
      "Epoch 51/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 1.0162 - mae: 0.8008 - val_loss: 1.7062 - val_mae: 1.0599\n",
      "Epoch 52/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9688 - mae: 0.7812 - val_loss: 1.6604 - val_mae: 1.0446\n",
      "Epoch 53/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.9268 - mae: 0.7635 - val_loss: 1.6174 - val_mae: 1.0259\n",
      "Epoch 54/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.8896 - mae: 0.7475 - val_loss: 1.5806 - val_mae: 1.0125\n",
      "Epoch 55/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.8567 - mae: 0.7325 - val_loss: 1.5492 - val_mae: 1.0037\n",
      "Epoch 56/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.8279 - mae: 0.7195 - val_loss: 1.5201 - val_mae: 0.9910\n",
      "Epoch 57/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.8025 - mae: 0.7075 - val_loss: 1.4951 - val_mae: 0.9817\n",
      "Epoch 58/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7805 - mae: 0.6969 - val_loss: 1.4734 - val_mae: 0.9704\n",
      "Epoch 59/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7608 - mae: 0.6872 - val_loss: 1.4548 - val_mae: 0.9635\n",
      "Epoch 60/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7436 - mae: 0.6787 - val_loss: 1.4376 - val_mae: 0.9561\n",
      "Epoch 61/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7285 - mae: 0.6708 - val_loss: 1.4255 - val_mae: 0.9498\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7153 - mae: 0.6637 - val_loss: 1.4134 - val_mae: 0.9490\n",
      "Epoch 63/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.7032 - mae: 0.6577 - val_loss: 1.4038 - val_mae: 0.9398\n",
      "Epoch 64/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6925 - mae: 0.6520 - val_loss: 1.3946 - val_mae: 0.9369\n",
      "Epoch 65/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6832 - mae: 0.6469 - val_loss: 1.3859 - val_mae: 0.9319\n",
      "Epoch 66/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6744 - mae: 0.6420 - val_loss: 1.3845 - val_mae: 0.9274\n",
      "Epoch 67/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6666 - mae: 0.6378 - val_loss: 1.3750 - val_mae: 0.9279\n",
      "Epoch 68/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6592 - mae: 0.6336 - val_loss: 1.3702 - val_mae: 0.9243\n",
      "Epoch 69/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6526 - mae: 0.6298 - val_loss: 1.3667 - val_mae: 0.9245\n",
      "Epoch 70/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6462 - mae: 0.6261 - val_loss: 1.3643 - val_mae: 0.9213\n",
      "Epoch 71/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6405 - mae: 0.6227 - val_loss: 1.3634 - val_mae: 0.9212\n",
      "Epoch 72/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6351 - mae: 0.6197 - val_loss: 1.3614 - val_mae: 0.9182\n",
      "Epoch 73/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6301 - mae: 0.6166 - val_loss: 1.3608 - val_mae: 0.9182\n",
      "Epoch 74/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.6255 - mae: 0.6139 - val_loss: 1.3589 - val_mae: 0.9193\n",
      "Epoch 75/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6209 - mae: 0.6114 - val_loss: 1.3580 - val_mae: 0.9157\n",
      "Epoch 76/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6166 - mae: 0.6087 - val_loss: 1.3619 - val_mae: 0.9173\n",
      "Epoch 77/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6126 - mae: 0.6060 - val_loss: 1.3593 - val_mae: 0.9174\n",
      "Epoch 78/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6087 - mae: 0.6041 - val_loss: 1.3618 - val_mae: 0.9176\n",
      "Epoch 79/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6050 - mae: 0.6021 - val_loss: 1.3631 - val_mae: 0.9173\n",
      "Epoch 80/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.6013 - mae: 0.5996 - val_loss: 1.3611 - val_mae: 0.9148\n",
      "Epoch 81/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5985 - mae: 0.5979 - val_loss: 1.3627 - val_mae: 0.9147\n",
      "Epoch 82/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5951 - mae: 0.5958 - val_loss: 1.3622 - val_mae: 0.9154\n",
      "Epoch 83/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5919 - mae: 0.5940 - val_loss: 1.3643 - val_mae: 0.9168\n",
      "Epoch 84/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5893 - mae: 0.5925 - val_loss: 1.3660 - val_mae: 0.9140\n",
      "Epoch 85/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5859 - mae: 0.5901 - val_loss: 1.3685 - val_mae: 0.9150\n",
      "Epoch 86/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5832 - mae: 0.5885 - val_loss: 1.3715 - val_mae: 0.9134\n",
      "Epoch 87/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5802 - mae: 0.5863 - val_loss: 1.3739 - val_mae: 0.9179\n",
      "Epoch 88/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5781 - mae: 0.5855 - val_loss: 1.3691 - val_mae: 0.9153\n",
      "Epoch 89/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5751 - mae: 0.5833 - val_loss: 1.3749 - val_mae: 0.9141\n",
      "Epoch 90/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5732 - mae: 0.5819 - val_loss: 1.3738 - val_mae: 0.9158\n",
      "Epoch 91/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5703 - mae: 0.5805 - val_loss: 1.3725 - val_mae: 0.9143\n",
      "Epoch 92/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5677 - mae: 0.5787 - val_loss: 1.3840 - val_mae: 0.9145\n",
      "Epoch 93/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5655 - mae: 0.5770 - val_loss: 1.3863 - val_mae: 0.9181\n",
      "Epoch 94/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5635 - mae: 0.5758 - val_loss: 1.3840 - val_mae: 0.9162\n",
      "Epoch 95/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5608 - mae: 0.5739 - val_loss: 1.3895 - val_mae: 0.9184\n",
      "Epoch 96/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5585 - mae: 0.5725 - val_loss: 1.3932 - val_mae: 0.9178\n",
      "Epoch 97/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5561 - mae: 0.5709 - val_loss: 1.3947 - val_mae: 0.9190\n",
      "Epoch 98/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5537 - mae: 0.5695 - val_loss: 1.3961 - val_mae: 0.9205\n",
      "Epoch 99/100\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.5514 - mae: 0.5682 - val_loss: 1.3976 - val_mae: 0.9180\n",
      "Epoch 100/100\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.5490 - mae: 0.5663 - val_loss: 1.4017 - val_mae: 0.9199\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit([train_data['user_id'], train_data['item_id']], \n",
    "                    train_data['rating'], \n",
    "                    validation_data=([test_data['user_id'], test_data['item_id']], test_data['rating']),\n",
    "                    epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89/89 [==============================] - 0s 907us/step - loss: 1.4017 - mae: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4017395973205566, 0.9199087619781494]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "\n",
    "model.evaluate([test_data['user_id'], test_data['item_id']], test_data['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot the model\n",
    "\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "for train_index, valid_index in kf.split(train_data):\n",
    "    train_set = train_data.iloc[train_index]\n",
    "    valid_set = train_data.iloc[valid_index]\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[user_input, movie_input], outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='mse', metrics=['mae'])\n",
    "    \n",
    "    model.fit([train_set['user_id'], train_set['item_id']], \n",
    "              train_set['rating'], \n",
    "              validation_data=([valid_set['user_id'], valid_set['item_id']], valid_set['rating']),\n",
    "              epochs=100, batch_size=16, verbose=0)\n",
    "    print(model.evaluate([test_data['user_id'], test_data['item_id']], test_data['rating']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
